{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQ3GQZB7bo6M"
      },
      "source": [
        "Step 9 Project 5 Nereida Heller"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iw5xhx64jICF"
      },
      "outputs": [],
      "source": [
        "#packages?\n",
        "!pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Qey74xT0boGX"
      },
      "outputs": [],
      "source": [
        "#import packages for deep learning\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "# from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pE52xADz3Py-",
        "outputId": "50983465-2cd6-4660-c42d-2ced95bbbdd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "#install the transformers library\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WygeyX2MQo8T"
      },
      "source": [
        "The simplest strategy is to use the pipeline method, where you select the task and the pre-trained model (there are multiple models available for many of the tasks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9pq4nvXSnMh",
        "outputId": "ea5b6e4e-45d0-49bb-f6ac-d0ab4ab46e04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline(\"sentiment-analysis\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erG8u-0GCP0b"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, set_seed\n",
        "# Here, 'text-generation' tells the pipeline to create a text generation model, and model='gpt2'\n",
        "# specifies that you want to use the GPT-2 model for this task.\n",
        "generator = pipeline('text-generation', model='gpt2')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, set_seed\n",
        "\n",
        "# Loading GPT-2 text gen model\n",
        "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "\n",
        "# Input + seed\n",
        "set_seed(100)\n",
        "input_text = \"In this project, we used which natural language processing to determine political party from politicians' tweets\"\n",
        "\n",
        "# Generate text\n",
        "output = generator(input_text, max_length=200, num_return_sequences=5, truncation=True)\n",
        "\n",
        "# Display the generated text\n",
        "for result in output:\n",
        "    print(result['generated_text'])\n",
        "    print(\"----\")"
      ],
      "metadata": {
        "id": "9C806zxImVvG",
        "outputId": "cd99d9ba-8966-46b2-b287-76097b65a423",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In this project, we used which natural language processing to determine political party from politicians' tweets on our platform, we used data that came out of Google+ and were very powerful in the results and could have influenced opinions of politicians through the algorithm.\n",
            "\n",
            "We started out by using this dataset from Wikipedia. Now, I think the best example is the data from the election results from Germany. That's how the election results came out of our data. We used this data for a lot of years prior to that. It's important to remember the elections from our last book. We were trying not to forget. For our most recent book, I wrote this book about the election results. I had to change the election results because the data was very large.\n",
            "\n",
            "We spent a lot of time working on our design, developing this algorithm and creating a dataset from it. It was a natural language processing solution, I'll refer to it as machine learning\n",
            "\n",
            "The data that we wanted was going to\n",
            "----\n",
            "In this project, we used which natural language processing to determine political party from politicians' tweets. As such, you can learn about the different types of presidential campaigns from Google Trends or Facebook.\n",
            "\n",
            "Note also that the time between the start of the election and the publication of the results is sometimes called \"election day\". We are using the \"election day\" as our official and unofficial calendar for the US Presidential election. The other important month in these polls are National Election Day and Labor Day. These are national periods when elections are fought over and whether or not political parties will be elected. You can find out more about the different calendars here.\n",
            "\n",
            "The data collected was collected from the American electorate in the US to obtain elections for two presidential electorates, in 2012 and 2014. To learn more about these elections, you must use the US election website or follow our political tracking and voting strategies.\n",
            "----\n",
            "In this project, we used which natural language processing to determine political party from politicians' tweets, and which word processing to use on a real-time basis.\n",
            "\n",
            "For that reason, we implemented various methods, which can be applied to both news source and text source from the Twitter app.\n",
            "\n",
            "This is a complete set of JavaScript code. In this post, I plan to explain how to get the list of tweets from the user, and how to use any JS package that works with JavaScript in React.\n",
            "\n",
            "Building React JS app\n",
            "\n",
            "I have created a new React JS app called React.js, which lets you build React with node and npm installed.\n",
            "\n",
            "Install npm:\n",
            "\n",
            "npm install --save-dev\n",
            "\n",
            "npm install -g http-fetch\n",
            "\n",
            "Run npm start --release.\n",
            "\n",
            "If you see \"Getting Started\", try:\n",
            "\n",
            "npm start --release\n",
            "\n",
            "Here is the code for the app:\n",
            "\n",
            "{-\n",
            "----\n",
            "In this project, we used which natural language processing to determine political party from politicians' tweets, which allows us to predict the actions of all the possible party leaders in an election campaign.\n",
            "\n",
            "What we found was that, in order for the results of popular opinion to reach its maximum, all political leaders should communicate with each other, or use their social media pages to coordinate political actions. This is the most natural form of communication in humans. The same neural networks that can generate these rules also help us predict political candidates' tweets and make good political speech decisions based on their actions.\n",
            "\n",
            "To test this idea, we trained a group of participants to receive two Facebook messages each time they heard a political party or opposition figure speak while watching a political show. Then, we combined this same training with the same stimulus video and social media posts to generate three lists which we named the participants. We used a neural network to look for words which express what a speech or political party would do, and for\n",
            "----\n",
            "In this project, we used which natural language processing to determine political party from politicians' tweets, rather than using keywords such as \"political\".\n",
            "\n",
            "Using the following criteria and data set, we were able to pick a political party and identify it as a party member.\n",
            "\n",
            "How did they identify a political party?\n",
            "\n",
            "We used the following filter.\n",
            "\n",
            "A few different things can happen in a real world election. First, there are lots of polls. For example, in the USA, the Republican has 48% (in 2014). Also, in Europe, there are about 80% (in 2013 or 2012) of the population (by way of demographics and party affiliation). For each party member, our formula was as follows:\n",
            "\n",
            "Republican Presidential Electoral Votes (RPM), US Presidential Electoral Votes (PMP), International Presidential Presidential Electoral Votes (IPS), and International Presidential Election Votes (IMEB). The main factors here were:\n",
            "\n",
            "- presidential election\n",
            "\n",
            "- a politician\n",
            "----\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "L_zANHRDhplZ",
        "pi2ikVCaoNct",
        "F9xyYBVVRZlE"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}